{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport scipy.sparse as sp\nimport os\nfrom typing import Tuple, Callable, Dict, Optional, List\nfrom sklearn.model_selection import train_test_split\ncwd = os.getcwd()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOADING DATA**","metadata":{}},{"cell_type":"code","source":"def load_data():\n    return pd.read_csv(\"../input/recommender-system-2020-challenge-polimi/data_train.csv\", \n                       sep=\",\", \n                       names=[\"user_id\", \"item_id\", \"rating\"],\n                       header=0,\n                       dtype={\"row\": np.int32,\n                               \"col\": np.int32,\n                               \"data\": np.int32})\ndef load_ICM():    \n    return pd.read_csv(\"../input/recommender-system-2020-challenge-polimi/data_ICM_title_abstract.csv\", \n                       sep=\",\", \n                       names=[\"item_id\", \"feature_id\", \"importance\"],\n                       header=0,\n                       dtype={\"row\": np.int32,\n                              \"col\": np.int32,\n                              \"data\": np.float})\n\nratings = load_data()\nICM = load_ICM()\n\nICM[\"importance\"] = ICM[\"importance\"]+1","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**MAPPING old ITEM_ID AND FEATURE_ID to new ITEM_ID AND FEATURE_ID.**\n\nADDING ALSO THE ONES WHICH ARE IN THE ICM BUT NOT IN THE URM\n","metadata":{"trusted":true}},{"cell_type":"code","source":"item_original_ID_to_index_dict = {}\n\nfor item_id in ratings[\"item_id\"].unique():\n    item_original_ID_to_index_dict[item_id] = len(item_original_ID_to_index_dict)\n\nprint(\"Unique item_id in the URM are {}\".format(len(item_original_ID_to_index_dict)))\n    \nfor item_id in ICM[\"item_id\"].unique():\n    if item_id not in item_original_ID_to_index_dict:\n        item_original_ID_to_index_dict[item_id] = len(item_original_ID_to_index_dict)\n        \nprint(\"Unique item_id in the URM and ICM are {}\".format(len(item_original_ID_to_index_dict)))\n\n\n\nfeature_original_ID_to_index_dict = {}\n\nfor feature_id in ICM[\"feature_id\"].unique():\n    feature_original_ID_to_index_dict[feature_id] = len(feature_original_ID_to_index_dict)\n\nprint(\"Unique feature_id in the URM are {}\".format(len(feature_original_ID_to_index_dict)))\n\n\n\n#original_feature_ID = 1185 \n#print(\"New index for feature '{}' is {}\".format(original_feature_ID, feature_original_ID_to_index_dict[original_feature_ID]))\n\n\n\nratings[\"item_id\"] = [item_original_ID_to_index_dict[item_original] for item_original in \n                                      ratings[\"item_id\"].values]\n\n\nICM[\"item_id\"] = [item_original_ID_to_index_dict[item_original] for item_original in \n                                      ICM[\"item_id\"].values]\n\nICM[\"feature_id\"] = [feature_original_ID_to_index_dict[feature_original] for feature_original in \n                                      ICM[\"feature_id\"].values]\n\n\n\n\nn_items = len(item_original_ID_to_index_dict)\nn_items_URM = len(ratings[\"item_id\"].unique())\nn_items_ICM = len(ICM[\"item_id\"].unique())\nn_users = len(ratings[\"user_id\"].unique())\nn_features = len(feature_original_ID_to_index_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TRAIN TEST SPLIT","metadata":{}},{"cell_type":"code","source":"def dataset_splits(ratings, ICM, num_users, num_items, validation_percentage: float, testing_percentage: float):\n    seed = 1234\n    \n    (user_ids_training, user_ids_test,\n     item_ids_training, item_ids_test,\n     ratings_training, ratings_test) = train_test_split(ratings.user_id,\n                                                        ratings.item_id,\n                                                        ratings.rating,\n                                                        test_size=testing_percentage,\n                                                        shuffle=True,\n                                                        random_state=seed)\n    \n    (user_ids_training, user_ids_validation,\n     item_ids_training, item_ids_validation,\n     ratings_training, ratings_validation) = train_test_split(user_ids_training,\n                                                              item_ids_training,\n                                                              ratings_training,\n                                                              test_size=validation_percentage,\n                                                             )\n    \n    urm_train = sp.csr_matrix((ratings_training, (user_ids_training, item_ids_training)), \n                              shape=(num_users, num_items))\n    \n    urm_validation = sp.csr_matrix((ratings_validation, (user_ids_validation, item_ids_validation)), \n                              shape=(num_users, num_items))\n    \n    urm_test = sp.csr_matrix((ratings_test, (user_ids_test, item_ids_test)), \n                              shape=(num_users, num_items))\n    \n    ICM = sp.csr_matrix((ICM[\"importance\"].values, \n                          (ICM[\"item_id\"].values, ICM[\"feature_id\"].values)),\n                        shape = (n_items, n_features))\n    \n    \n    return urm_train, urm_validation, urm_test, ICM\n\n\nurm_train, urm_validation, urm_test, ICM_final = dataset_splits(ratings,\n                                                     ICM,\n                                                     num_users=n_users, \n                                                     num_items=n_items , \n                                                     validation_percentage=0.20, \n                                                     testing_percentage=0.10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef vector_similarity(ICM: sp.csc_matrix, shrink: int):\n    ICM = ICM.tocsr()  #fa più veloce (3.50 min contro 6.2)\n    item_norms = np.sqrt(np.array(ICM.T.power(2).sum(axis=0))).ravel()\n \n    num_items = ICM.shape[0]\n    ICM_t = ICM.T\n    weights = np.empty(shape=(num_items, num_items))\n    for item_id in range(num_items):\n        numerator_vector = ICM[item_id].dot(ICM_t).A.flatten()#toarray().ravel()\n       \n        denominator_vector = item_norms[item_id] * item_norms + shrink + 1e-6\n   \n        weights[item_id] = numerator_vector / denominator_vector\n        \n    np.fill_diagonal(weights, 0.0)\n    return weights\n\n\ndef matrix_similarity2(ICM: sp.csc_matrix, shrink: int):      \n    item_norms = np.sqrt(\n        np.sum(ICM.power(2), axis=1)\n    ).A\n    \n   \n    #item_norms = np.sqrt(np.array(ICM.T.power(2).sum(axis=0))).ravel()\n\n    numerator = ICM.dot(ICM.T)\n  \n    denominator = item_norms.dot(item_norms.T) + shrink + 1e-6\n   \n    weights = numerator / denominator\n    np.fill_diagonal(weights, 0.0)\n    \n    return weights\n\ndef matrix_similarity(ICM: sp.csc_matrix, shrink: int, block_size: int):\n    ICM = ICM.tocsr()  #fa più veloce (quasi la metà)\n\n    item_norms = np.sqrt(\n            np.sum(ICM.power(2), axis=1)\n            ).A\n\n    n_items = ICM.shape[0]\n\n    #block_size = 500\n    blocks_start_positions = range(0, n_items, block_size)\n    denominator = item_norms.dot(item_norms.T) + shrink + 1e-6\n    weights = np.empty(shape=(n_items, n_items))\n    numerator = np.array([]).reshape(0, 25975)\n    \n    for start_pos in blocks_start_positions:\n        end_pos = min(start_pos + block_size, n_items)\n        numerator = np.concatenate((numerator,ICM[start_pos:end_pos].dot(ICM.T).toarray()))\n        \n    weights = numerator / denominator\n    np.fill_diagonal(weights, 0.0)\n    return weights\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CBFItemKNN(object):\n    def __init__(self, shrink: int):\n        self.shrink = shrink\n        self.weights = None\n    \n    \n    def fit(self, urm_train: sp.csc_matrix, block_size: int, similarity_function):\n        if not sp.isspmatrix_csc(urm_train):\n            raise TypeError(f\"We expected a CSC matrix, we got {type(urm_train)}\")\n        \n        self.weights = similarity_function(urm_train, self.shrink, block_size)\n        \n    def recommend(self, user_id: int, urm_train: sp.csr_matrix, at: Optional[int] = None, remove_seen: bool = True):\n        user_profile = urm_train[user_id]\n        \n        ranking = user_profile.dot(self.weights).flatten()\n        \n        if remove_seen:\n            user_profile_start = urm_train.indptr[user_id]\n            user_profile_end = urm_train.indptr[user_id+1]\n            \n            seen_items = urm_train.indices[user_profile_start:user_profile_end]\n            \n            ranking[seen_items] = -np.inf\n            \n        ranking = np.flip(np.argsort(ranking))\n        return ranking[:at]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"A = np.array([2,5,1,3,7,3,89,2])\nB = np.argsort(A)\nB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall(recommendations: np.array, relevant_items: np.array) -> float:\n    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n    \n    recall_score = np.sum(is_relevant) / relevant_items.shape[0]\n    \n    return recall_score\n    \n    \ndef precision(recommendations: np.array, relevant_items: np.array) -> float:\n    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n    \n    precision_score = np.sum(is_relevant) / recommendations.shape[0]\n\n    return precision_score\n\ndef mean_average_precision(recommendations: np.array, relevant_items: np.array) -> float:\n    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n    \n    precision_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n\n    map_score = np.sum(precision_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n\n    return map_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluator(recommender: object, urm_train: sp.csr_matrix, urm_test: sp.csr_matrix):\n    recommendation_length = 10\n    accum_precision = 0\n    accum_recall = 0\n    accum_map = 0\n    \n    num_users = urm_train.shape[0]\n    \n    num_users_evaluated = 0\n    num_users_skipped = 0\n    for user_id in range(num_users):\n        user_profile_start = urm_test.indptr[user_id]\n        user_profile_end = urm_test.indptr[user_id+1]\n        \n        relevant_items = urm_test.indices[user_profile_start:user_profile_end]\n        \n        if relevant_items.size == 0:\n            num_users_skipped += 1\n            continue\n            \n        recommendations = recommender.recommend(user_id=user_id, \n                                               at=recommendation_length, \n                                               urm_train=urm_train, \n                                               remove_seen=True)\n        \n        accum_precision += precision(recommendations, relevant_items)\n        accum_recall += recall(recommendations, relevant_items)\n        accum_map += mean_average_precision(recommendations, relevant_items)\n        \n        num_users_evaluated += 1\n        \n    \n    accum_precision /= max(num_users_evaluated, 1)\n    accum_recall /= max(num_users_evaluated, 1)\n    accum_map /=  max(num_users_evaluated, 1)\n    \n    return accum_precision, accum_recall, accum_map, num_users_evaluated, num_users_skipped","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hyperparameter_tuning(ICM_matrix, shrinks):\n    #shrinks = [0,1,5,10,50, 75, 100]\n    #shrinks = [7, 8, 9, 10, 11, 12, 18, 20, 25]\n    results = []\n    for shrink in shrinks:\n        print(f\"Currently trying shrink {shrink}\")\n        \n        itemknn_recommender = CBFItemKNN(shrink=shrink)\n        itemknn_recommender.fit(ICM_matrix.tocsc(), 8000, matrix_similarity)\n        \n        ev_precision, ev_recall, ev_map, _, _ = evaluator(itemknn_recommender, urm_train, urm_validation)\n        \n        results.append((shrink, (ev_precision, ev_recall, ev_map)))\n        \n    return results\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ICM_final[725,96])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shrinks = [7, 8, 9, 10, 11, 12, 18, 20, 25]\n#hyperparameter_results = hyperparameter_tuning(ICM_final, shrinks)\n#hyperparameter_results\n#best_shrink = 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nr3 = CBFItemKNN(shrink=7)\nr3.fit(ICM_final.tocsc(), 6000, matrix_similarity)\n\n#vector_similarity statistics:\n#3min 50 sec CSR\n#6min 20 sec CSC\n\n#matrix_similarity statistics:\n#2min 5 sec block 100, CSC\n#58 sec block 1000, CSC\n#41 sec block 3000, CSC\n#25 sec block 3000, CSR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r3.weights[0].max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\naccum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped = evaluator(recommender3, \n                                                                                            urm_train+urm_validation, \n                                                                                            urm_test)\n\nprint(accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}